# 제 3장: 정렬 (sort)
## 다양한 정렬 알고리즘
| 정렬 알고리즘 | 특징 |
|---|---|
| • Bubble sort<br>• Insertion sort<br>• Selection sort | simple, slow |
| • Quicksort<br>• Merge sort<br>• Heap sort | fast |
| • Radix sort | O(N) |

## 기본적인 정렬 알고리즘
### 선택 정렬 (selection sort)
- 각 루프마다:
  - 최대 원소를 찾는다
  - 최대 원소와 맨 오른쪽 원소를 교환한다
  - 맨 오른쪽 원소를 (루프의 탐색 범위에서) 제외한다  
→ 하나의 원소만 남을 때까지 위의 루프를 반복

#### 선택 정렬 알고리즘즘
```
selectionSort(A[], n)
{
    for last <- n downto 2    {
        find max A[k] among A[1...last] // 가장 큰 수 A[k]를 찾는다;
        A[k] <-> A[last];  // 교환
    }
}
```
- for 루프는 총 $n-1$회 반복
- 각 루프마다 가장 큰 수를 찾기 위한 비교 횟수: $n-1, n-2, \cdots, 2, 1$
(last개의 수 중에서 최대값을 찾기 위해선 last-1번의 비교가 필요)
- 교환은 상수 작업
→ 시간 복잡도 $T(n) = (n-1) + (n-2) + \cdots + 2 + 1 = \frac{n(n-1)}{2} = O(n^2)$


- 어떤 입력에 대해서도 동일한 작업을 수행하기 때문에 최선, 최악, 평균의 경우를 구분할 필요가 없이 항상 동일한 시간복잡도를 가짐

### 버블 정렬 (bubble sort)
- 기본 아이디어는 selection sort와 유사함: 정렬할 데이터 중에서 가장 큰 값을 찾아 맨 마지막 자리로 옮긴 뒤, 그 데이터는 제외하고 같은 작업을 계속 반복
- **다만,** 최댓값을 찾고 이를 마지막 요소로 만드는 세부적인 방법이 다름
→ 각 루프마다:
  - $i$번째 값을 $i+1$번째 값과 비교한다
  - $i$번째 값이 $i+1$번째 값보다 크다면 두 요소의 위치를 교환한다
  - 맨 오른쪽 원소를 (루프의 탐색 범위에서) 제외한다

#### 버블 정렬 알고리즘

```
bubbleSort(A[], n)
{
    for last <- n downto 2    {
        for i <- 1 to last - 1    {
            if (A[i] > A[i+1]) then A[i] <-> A[i+1]
        }
    }
}
```
  
시간 복잡도: $T(n) = (n-1) + (n-2) + \cdots + 2 + 1 = \frac{n(n-1)}{2} = O(n^2)$

### 선택 정렬과 버블 정렬의 비교
두 정렬 방식 모두 **비교** 횟수는 각 루프마다 $n-1, n-2, \cdots, 2, 1$번으로 동일함 **그러나:**
- 선택 정렬은 각 루프마다  $1$회의 **교환**이 일어나는 반면, 버블 정렬은 최대 $n-1, n-2, \cdots, 2, 1$회의 교환이 일어날 수 있음
- **대신,** 버블 정렬의 경우엔 주어진 배열이 이미 정렬되었는지 아닌지를 해당 루프에서 **교환이 한번이라도 일어났는지 여부**를 통해 확인이 가능하며, 정렬을 조기 종료 시킬 수 있음. 따라서 버블 정렬의 경우엔 최선의 경우 시간복잡도가 $O(n)$이 됨.
- 선택 정렬은 교환 횟수가 버블 정렬보다 일반적으로 적은 대신, 배열이 이미 정렬되었는지 감지가 불가능하여 어떤 경우에도 $O(n^2)$의 시간복잡도를 가짐.
  
두 정렬 모두 최악의 경우, 시간복잡도는 $O(n^2)$으로 동일하지만, 실제 실행시간을 상수 계수까지 비교해본다면 차이가 발생함.

#### 최악의 경우 연산 횟수 비교 ($n=1000$)

| 구분 | 선택 정렬 | 버블 정렬 | 비율 |
|---|---|---|---|
| **비교 횟수** | $\frac{n(n-1)}{2} = 499,500$ | $\frac{n(n-1)}{2} = 499,500$ | 1:1 |
| **교환 횟수** | $n-1 = 999$ | $\frac{n(n-1)}{2} = 499,500$ | 1:500 |
| **대입 연산** | $3(n-1) = 2,997$ | $\frac{3n(n-1)}{2} = 1,498,500$ | 1:500 |
| **총 연산** | $499,500 + 2,997 \approx 502,000$ | $499,500 + 1,498,500 \approx 2,000,000$ | 1:4 |

### 삽입 정렬 (insertion sort)
각 요소를 앞에서부터 차례대로 이미 정렬된 배열 부분과 비교하여, 자신의 위치를 찾아 삽입함으로써 정렬을 완성하는 알고리즘이다.  
(이미 정렬이 된 $k-1$개의 값이 있고, 거기에 하나를 추가하여 $k$개가 정렬되도록 만든다 생각하면 됨)

#### 삽입 위치를 어떻게 정할 것인가?
1. 맨 앞에서 부터 비교를 시작하여, 새로 넣고자하는 요소보다 크거나 같은 값이 나타나면 (혹은 맨 뒤에 도달 할 때 까지) 그 값 앞에 삽입 
2. 맨 뒤에서 부터 비교를 시작하여, 새로 넣고자하는 요소보다 작거나 같은 값이 나타나면 (혹은 맨 앞에 도달 할 때 까지) 그 값 뒤에 삽입  

두 방법이 대칭적인 것으로 동일할 것이라 생각되나, 그렇지 않을 수도 있음:  
**정렬할 데이터가 배열에 저장되어있기 때문에**, 1번 방법의 경우, 새로 추가하는 요소보다 작은 값들과 모두 비교를 해서 삽입할 위치를 찾았어도, 결국 그 위치에 삽입하기 위해선 새 요소보다 큰 값들을 모두 뒤로 한칸씩 밀어줘야하므로 결국 모두 순회하게 됨. 반면, 2번 방법의 경우엔 새 요소보다 작은 값들까지 순회할 필요가 없음. 

*값을 뒤로 한칸씩 밀어야하기 때문에 추가되는 요소가 지워지지 않도록 임시변수에 저장해야 함!*

#### 삽입정렬 알고리즘
```
insertionSort(A[], n)  // sort array A[1, ..., n]
{
    for i <- 2 to n    {  --- (1)
        find a correct position in A[1, ..., i] and insert A[i]  --- (2)
    }
}
```
수행시간:  
1. for 루프는 $n-1$번 반복
2. 삽입은 최악의 경우 $i-1$번 비교
→ 최악의 경우 $T(n) = (n-1) + (n-2) + \cdots + 2 + 1 = O(n^2)$
→ 최선의 경우(이미 정렬되어있는 경우)엔 $T(n) = 1 + 1 + \cdots + 1 = n - 1 = O(n)$

약간의 오버헤드까지 고려하면 선택/버블 정렬보다 삽입 정렬이 좀 더 빠르다. 특히, 버블 정렬도 최선의 경우가 $O(n)$ 또는 $n-1$로 동일해보이지만, 버블 정렬은 추가로 교환이 발생했는지 체크(`!(swapped)`) 해야하거나 하는 등의 (아주 미미한) 오버헤드가 있긴 함.

## 분할정복법
- 분할: 해결하고자 하는 문제를 작은 크기의 *동일한* 문제들로 분할
- 정복: 각각의 작은 문제를 *순환적*으로 해결
- 합병: 작은 문제의 해를 *합하여*(merge) 원래 문제에 대한 해를 구함

e.g., 합병정렬(merge sort)과 퀵정렬(quick sort)이 분할정복법(divide and conquer)에 해당 됨.

### 합병정렬 (merge sort)
- 데이터가 저장된 배열을 절반으로 나눔 (실제로 무슨 작업을 하는 건 아님)
- 각각을 순환적으로 정렬 (재귀적으로 함수 호출)
- 정렬된 두 개의 배열을 합쳐 전체를 정렬 (즉, 정렬을 합병 과정 중에 진행) <-- 실제 코딩을 할 필요가 있는 부분 
```
e.g., 배열 [5, 2, 4, 7]
5 / 2 / 4 / 7
2 5 / 4 7
2 4 5 7
```

#### 두개의 정렬된 리스트를 하나의 정렬된 리스트로 합치는 법
길이가 정렬된 두 배열의 길이의 합인 *추가배열*을 이용
```
e.g.,
// 각각의 배열이 이미 정렬되어 있으므로
// A 또는 H중 하나가 전체중에서 가장 작은 값이 됨 (A[i]와 A[j] 비교)
A G L O R / H I M S T  
i           j

0 0 0 0 0 0 0 0 0 0
k
-----------------------
A G L O R / H I M S T  
  i         j

A 0 0 0 0 0 0 0 0 0
  k
-----------------------
A G L O R / H I M S T  
    i       j

A G 0 0 0 0 0 0 0 0
    k
-----------------------
A G L O R / H I M S T  
    i         j

A G H 0 0 0 0 0 0 0
      k
-----------------------
A G L O R / H I M S T  
    i           j

A G H I 0 0 0 0 0 0
        k
... (반복)
```

#### 합병 정렬 알고리즘

```
mergeSort(A[], p, r)  // 배열 A의 index p에서 r까지 데이터를 정렬
{
    if (p < r) then {
        q <- (p + r) / 2;  // p, r의 중간 지점 계산
        mergeSort(A, p, q);
        mergeSort(A, q+1, r);
        merge(A, p, q, r);
    }
}

merge(A[], p, q, r)
{
    정렬되어 있는 두 배열 A[p ... q]와 A[q+1 ... r]을 합하여
    정렬된 하나의 배열 A[p ... r]을 만든다.
}
```

```
#define _CRT_SECURE_NO_WARNINGS
#include <stdio.h>
#include <stdlib.h>

void merge(int data[], int p, int q, int r) {
	int i = p;
	int j = q + 1;
	int k = 0;

	int size = r - p + 1;
	int* temp = (int*)malloc(size * sizeof(int));  // 주의: 매호출 malloc 하는 것은 매우 느림

	while (i <= q && j <= r) {
		if (data[i] <= data[j]) {
			temp[k++] = data[i++];
		}
		else {
			temp[k++] = data[j++];
		}
	}

	while (i <= q) {
		temp[k++] = data[i++];
	}
	while (j <= r) {
		temp[k++] = data[j++];
	}

	for (int i = 0; i <= size; i++) {
		data[p + i] = temp[i];
	}
	
	free(temp);

}
```

시간복잡도:

$$
T(n) = \begin{cases}
2T\left(\frac{n}{2}\right) + n & \text{if } n > 1 \\
O(1) & \text{if } n = 1
\end{cases} = O(n\log n)
$$

### 퀵 정렬 (quick sort)
분할: 배열을 임의의 피벗(pivot)을 기준으로 나눈다 - pivot보다 작은 값들 / pivot보다 큰 값 (따라서 항상 반반으로 쪼개지지 않음)  
정복: 각 부분을 순환적으로 정렬한다 (= 각각을 다시 퀵 정렬)  
합병: nothing to do

```
1) 정렬할 배열이 주어짐. 마지막 수를 피벗(pivot)으로 삼는다
31 8 48 73 11 3 20 29 65 <15>

2) 피벗을 기준으로 분할 (재배치)
8 11 3 <15> 31 48 20 29 65 73

3) 피벗의 좌우를 각각 순환적으로 정렬한다 (과정은 생략)
3 8 11 <15> 20 29 31 48 65 73 
```

#### 퀵 정렬 알고리즘
```
quickSort(A[], p, r)  // 배열 A의 인덱스 p부터 r까지 정렬한다
{
    if (p < r) then {  // 배열의 길이가 2 이상 일때만 (즉, 1 이하면 종료)
		q = partition(A, p, r);  // 분할 (q = pivot의 위치)
		quickSort(A, p, q - 1);  // 왼쪽 부분 배열 정렬
		quickSort(A, q + 1, r);  // 오른쪽 부분 배열 정렬
	}
}

partition(A[], p, r)
{
	배열 A[p, ..., r]의 원소들을 A[r]을 기준으로 양쪽으로 재배치하고 A[r]이 자리한 위치를 return;
	(즉, 주어진 범위의 마지막 원소를 피벗으로 분할 후, 피벗의 위치를 반환)
}
```

#### Partition 알고리즘
피벗은 마지막에 그대로 두고 그 앞의 배열을 먼저 피벗보다 작은 요소들의 영역, 큰 요소들의 영역 두개로 분할 한 뒤, 큰 요소들의 영역의 첫번째 요소를 마지막에 피벗과 교환한다. 따라서, 각각의 요소를 피벗과 한번씩 비교를 해야한다.  
```
p: 정렬의 시작 index
r: 정렬의 끝 idnex
i: pivot보다 작은 값들 중 마지막 값의 index (p - 1에서 시작) = '여기까지 정렬이 완료되었음'을 나타내는 index
j: 지금 검사하려는 값의 index (i에서 시작)

Partition(A[], p, r)
{
	x = A[r];
	i = p - 1;  // 아직 pivot보다 작다고 판단된 요소가 없으므로 out-of-index에서 시작
	for (j = p; j <= r - 1; j++) {
		if (A[j] <= x) {
			i = i + 1;
			exchange A[i] and A[j];
		}
	}
	exchange A[i + 1] and A[r];  // pivot과 pivot보다 큰 요소중 첫 요소와 교환  
	return i + 1;
}
```

시간복잡도:  
1. 분할 (Partition): 데이터가 $n$개라면, 모든 데이터를 pivot과 한번씩, 즉, 총 $n-1$회 비교하면 됨 ($+1$ 마지막 피벗 교환). 
2. 순환 (Recursion): 그럼 이 비교를 몇번 재귀/순환적으로 반복할까? 최악의 경우, 항상 한쪽은 $0$개, 다른 쪽은 $n-1$개로 분할 되면 quickSort 함수 자체가 총 $n - 1$회 호출 됨 (재귀의 조건이 `if (p < r)`이므로 배열의 길이가 1이하가 되면 base case 도달)

$$
\begin{aligned}
T(n) &= T(0) + T(n-1) + \Theta(n) \\
&= T(n-1) + \Theta(n) \\
&= T(n-2) + T(n-1) + \Theta(n-1) + \Theta(n) \\
&\quad \vdots \\
&= \Theta(1) + \Theta(2) + \cdots + \Theta(n-1) + \Theta(n) \\
&= \Theta(n^2)
\end{aligned}
$$

($\Theta$는 partition 비용, $T$는 재귀호출된 함수 비용)

모순적이게도, 이미 정렬된 입력 데이터의 경우가 최악의 경우가 됨 (마지막 원소를 피봇으로 선택하는 경우)

반면, 항상 절반으로 분할되는 경우 (최상의 경우 - 분할 시 pivot이 항상 중앙에 놓이는 경우):

$$
\begin{aligned}
T(n) = 2T(n/2) + \Theta(n) = \Theta(n \log n)
\end{aligned}
$$
  
**Q. 이딴게 quick? 최선의 경우에나 합병 정렬이랑 비슷한데?**  
A. 항상 절반씩 나누거나 (최선), 항상 $n-1$, $0$개씩 나누거나 (최악) 하는 경우는 사실 그리 확률이 높지 않음. 대충 한쪽이 적어도 $1/9$ 이상이 되도록 분할된다면? (이 정도면 현실적인 가정) -> 최악의 경우에 필요한 순환/재귀 횟수 = 항상 $9/10$을 가져가는 쪽의 순환/재귀 횟 = $k = \log{10/9}n = \theta(\log n)$. 분할의 연산은 각 재귀 호출마다 $n$회이므로 시간복잡도는 $O(n \log n)$.  

이 예시가 의미하는 바는 퀵 정렬의 성능은 partition이 얼마나 잘 balance되느냐에 달려있다는 것. 즉, 분할이 아주 극단적으로 일어나지만 않는다면 충분히 빠르다.

  
#### 퀵정렬 평균시간복잡도
- '평균' 혹은 '기대값'이란?

$$
A(n) = \sum_{\forall \text{ input instance } I \text{ of size } n} p(I)T(I)
$$

$p(I)$: $I$가 입력으로 들어올 확률
$T(I)$: $I$를 정렬하는데 걸리는 시간

- 그러나 실제로는 $p(I)$를 모름
- $p(I)$에 관한 적절한 가정을 한 후 분석
- e.g., 모든 입력 인스턴스가 동일한 확률을 가진다면 $p(I) = \frac{1}{n!}$ (입력이 $1$부터 $n$까지의 정수의 permutation이라고 가정)
  
$$A(n) = \frac{2}{n}\sum_{i=0}^{n-1} A(i) + \Theta(n) = \Theta(n\log_2 n)$$


#### Pivot의 선택
- 첫번째 값이나 마지막 값을 피봇으로 선택
  - 이미 정렬된 데이터 혹은 거꾸로 정렬된 데이터가 최악의 경우
  - 현실의 데이터는 랜덤하지 않으므로 정렬된 데이터가 입력으로 들어올 가능성이 매우 높음  
  - 따라서 좋은 방법이라고 할 수 없음
- "Median of Three"
  - 첫번째 값과 마지막 값, 그리고 가운데 값 중에서 중간값(median)을 피벗으로 선택
  - 최악의 경우 시간복잡도가 달라지지는 않음 (여전히 $O(n^2)$)
- Randomized Quicksort
  - 피벗을 랜덤하게 선택
  - no worst case instance, but worst case execution (이전의 두 방법의 경우엔 입력 데이터 - case - 에 따라 최악의 경우가 결정되는 반면, 랜덤의 경우 내가 주사위를 얼마나 잘 굴리냐 - execution - 에 따라 최악이 결정됨) 
  - 평균 시간복잡도 $O(n\log n)$
